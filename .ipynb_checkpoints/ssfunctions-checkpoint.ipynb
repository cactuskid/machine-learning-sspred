{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.py                 functions.pyc          ssfunctions.ipynb\r\n",
      "config.pyc                learn.py               SSfunctions.py\r\n",
      "daskClusterLSF.py         learnssmodel.py        sspredictor.py\r\n",
      "Dataset.py                lsfconfig.py           test.py\r\n",
      "distributedTensorFlow.py  physicalpropTable.csv  test.pyc\r\n",
      "\u001b[0m\u001b[01;34mexamples\u001b[0m/                 README.md\r\n",
      "functions.py              \u001b[01;34mSSdataset\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    return sechunks\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from Bio import SeqIO\n",
    "import glob\n",
    "import pdb\n",
    "import functools\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense , LSTM , Bidirectional\n",
    "\n",
    "def protsec2numpy(sec, windowlen, propdict=None, verbose= False):\n",
    "\t#window should be an odd number\n",
    "\t#slice up the sequence into window sized chunks\n",
    "\tpadding = (windowlen-1)/2\n",
    "\ttry:\n",
    "\t\toriginallen = len(sec)\n",
    "\texcept TypeError:\n",
    "\t\treturn None\n",
    "\tsec = ['-']*int(padding) + list(sec) + int(padding)*['-']\n",
    "\tsechunks=  [ [ x for x in str(sec[i:i + windowlen]) ]  for i in range(0, originallen)]\n",
    "    return sechunks\n",
    "\n",
    "def seq2vec(seq, propdict, verbose = False):\n",
    "\t#countmat is length of sequence\n",
    "\tpropmat = np.zeros(( len(propdict) , len(seq) ))\n",
    "\tseqvec = np.asarray( [char for char in seq] )\n",
    "\tfor i,prop in enumerate(propdict):\n",
    "\t\tvals = np.vectorize(propdict[prop].get)(seqvec)\n",
    "\t\tpropmat[i,:] = vals.ravel()\n",
    "\treturn propmat\n",
    "\n",
    "def econdedDSSP(ssStr,intdico,encoder):\n",
    "\t'''\n",
    "\tH = alpha-helix\n",
    "\tB = residue in isolated beta-bridge\n",
    "\tE = extended strand, participates in beta ladder\n",
    "\tG = 3-helix (310 helix)\n",
    "\tI = 5 helix (pi-helix)\n",
    "\tT = hydrogen bonded turn\n",
    "\tS = bend\n",
    "\t'''\n",
    "\ttry:\n",
    "\t\tintvec = np.asarray([ intdico[char] for char in ssStr])\n",
    "\t\tonehot = encoder.transform(intvec.reshape(-1, 1))\n",
    "\t\treturn onehot\n",
    "\texcept:\n",
    "\t\t#print(ssStr)\n",
    "\t\treturn(ssStr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/cactuskid/Dropbox/machine_learning/SSdataset/ss.txt']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def loadDict(csvfile):    \n",
    "\twith open(csvfile , 'r') as filestr:\n",
    "\t\tfinal = {}\n",
    "\t\tpropdict= csv.DictReader(filestr)\n",
    "\t\tfor row in propdict:\n",
    "\t\t\tfor key in row.keys():\n",
    "\t\t\t\tif key != 'letter Code' and key!= 'Amino Acid Name' and key!= '':\n",
    "\t\t\t\t\tif key not in final:\n",
    "\t\t\t\t\t\tfinal[key]={}\n",
    "\t\t\t\t\tfinal[key][row['letter Code']] = float(row[key])\n",
    "\treturn final\n",
    "\n",
    "\n",
    "def datagenerator(fastas , n=100 , windowlen= 13, embeddingprot=None , embeddingSS=None):\n",
    "\t#yield string for x and y to make a df block of n sequences to learn with\n",
    "\tfor fasta in fastas:\n",
    "\t\tfastaIter = SeqIO.parse(fasta, \"fasta\")\n",
    "\t\tseqDict={}\n",
    "\t\tfor seq in fastaIter:\n",
    "\t\t\tchainID = str(seq.description)\n",
    "\t\t\tID = chainID[0:6]\n",
    "\t\t\tif ID not in seqDict:\n",
    "\t\t\t\tseqDict[ID]= {}\n",
    "\t\t\tif 'secstr' in seq.description:\n",
    "\t\t\t\tseqDict[ID]['SS']= ''.join(seq.seq)\n",
    "\t\t\telse:\n",
    "\t\t\t\tseqDict[ID]['AA']= ''.join(seq.seq)\n",
    "\n",
    "\t\t\tif len(seqDict)>n:\n",
    "\t\t\t\tdf = pd.DataFrame.from_dict(seqDict, orient= 'index')\n",
    "\t\t\t\tyield df\n",
    "\t\t\t\tseqDict={}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#init encoder for ss\n",
    "sspath = '/home/cactuskid/Dropbox/machine_learning/SSdataset/'\n",
    "fastas = glob.glob(sspath +'*.txt')\n",
    "print(fastas)\n",
    "\n",
    "#window of amino acids to inspect in lstm\n",
    "windowlen = 13\n",
    "\n",
    "#first part of the network, layered lstm\n",
    "LSTMoutdim = 30\n",
    "LSTMlayers = 3\n",
    "#second part of the network, dense decoder\n",
    "Denselayers = 3\n",
    "Denseoutdim = 30\n",
    "#save itnerval\n",
    "saveinterval = 100\n",
    "verbose = True\n",
    "\n",
    "proppath = '/home/cactuskid/Dropbox/machine_learning/physicalpropTable.csv'\n",
    "propdict = loadDict(proppath)\n",
    "\n",
    "#pdb.set_trace()\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit( np.asarray( np.asarray(range(7)).reshape(-1,1) ) )\n",
    "\n",
    "\n",
    "\n",
    "intdico = { charval : int(i) for i,charval in enumerate(['H', 'B', 'E', 'G', 'I', 'T', 'S'] ) }\n",
    "ssencoder = functools.partial( econdedDSSP , intdico= intdico , encoder = encoder)\n",
    "prot2sec = functools.partial( protsec2numpy , windowlen= windowlen , propdict= propdict )\n",
    "generator = datagenerator(fastas, n = 10 , windowlen= windowlen ,  embeddingprot = prot2sec , embeddingSS = ssencoder)\n",
    "\n",
    "testdf = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       AA  \\\n",
      "101M:A  MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...   \n",
      "102L:A  MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAAKSE...   \n",
      "102M:A  MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...   \n",
      "103L:A  MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNSLDAAK...   \n",
      "103M:A  MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...   \n",
      "104L:A  MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSAA...   \n",
      "104L:B  MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSAA...   \n",
      "104M:A  VLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDRF...   \n",
      "105M:A  VLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDRF...   \n",
      "106M:A  MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...   \n",
      "107L:A  MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKGEL...   \n",
      "\n",
      "                                                       SS  \n",
      "101M:A  HHHHHHHHHHHHHHGGGHHHHHHHHHHHHHHHGGGGGGTTTTTSHH...  \n",
      "102L:A  HHHHHHHHHEEEEEETTSEEEETTEEEESSSTTTHHHHHHHHHHTS...  \n",
      "102M:A  HHHHHHHHHHHHHHGGGHHHHHHHHHHHHHHHGGGGGGTTTTTSHH...  \n",
      "103L:A  HHHHHHHHHEEEEEETTSEEEETTEEHHHHHHHHHHHHTSTTBHHH...  \n",
      "103M:A  HHHHHHHHHHHHHHGGGHHHHHHHHHHHHHHHGGGGGGTTTTTSHH...  \n",
      "104L:A  HHHHHHHHTSBEETTSEEETTTEEEETTHHHHHHHHHHHHTSTTBH...  \n",
      "104L:B  HHHHHHHHHSBEETTSEETTTSSHHHHHHHHHHHSSTTBHHHHHHH...  \n",
      "104M:A  HHHHHHHHHHHHHHGGGHHHHHHHHHHHHHHHGGGGGGTTTTTSHH...  \n",
      "105M:A  HHHHHHHHHHHHHHHHTHHHHHHHHHHHHHHHHHHHTTTTTTTSHH...  \n",
      "106M:A  HHHHHHHHHHHHHHGGGHHHHHHHHHHHHHHHGGGGGGTTTTTSHH...  \n",
      "107L:A                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "print(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = next(testdf.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDRVKHLKTEAEMKASEDLKKHGVTVLTALGAILKKKGHHEAELKPLAQSHATKHKIPIKYLEFISEAIIHVLHSRHPGNFGADAQGAMNKALELFRKDIAAKYKELGYQG\n"
     ]
    }
   ],
   "source": [
    "print(row[1]['AA'])\n",
    "\n",
    "rowout = protsec2numpy(row[1]['AA'], 11, propdict=None, verbose= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-61-4fe4f3f228b2>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-4fe4f3f228b2>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    ''join(rowout[0])\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from array import array\n",
    "''.join(rowout[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
